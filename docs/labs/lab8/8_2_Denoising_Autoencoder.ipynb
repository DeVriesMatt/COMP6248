{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ff3f3e0205bff3e4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 2: Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e42398fb4955fba",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Execute this code block to install dependencies when running on colab\n",
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    from os.path import exists\n",
    "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2122f281579eb211",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Extend the Autoencoder you implemented in Part 1 to a Denoising Autoencoder\n",
    "\n",
    "Recall from the lecture, a denoising autoencoder's architecture is very similar to a standard autoencoder. The difference is the input to the autoencoder has noise added to it. However, when computing the loss function, make sure the original (non-noisy) version is used for backpropagation.\n",
    "\n",
    "Again, let's start by loading the Fashion-MNIST dataset and transforming it to a flattened tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 256\n",
    "image_dim = 784  # [flattened]\n",
    "\n",
    "# dataset construction\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert to tensor\n",
    "    transforms.Lambda(lambda x: x.view(image_dim)) # flatten into vector\n",
    "    ])\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c4a66cd9fec76585",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "## Build a Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the Encoder and Decoder classes for your denoising autoencoder, called DN_Encoder, DN_Decoder, respectively. You can define these architectures how you like; some suggested architectures are given as comments in the classes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-b4d66dec3d57>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b4d66dec3d57>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    class DN_Decoder(nn.Module):\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "class DN_Encoder(nn.Module):\n",
    "    '''\n",
    "    Denoising encoder with a single input, hidden and output layer\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DN_Encoder, self).__init__()\n",
    "        ## WRITE CODE HERE\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## WRITE CODE HERE\n",
    "\n",
    "class DN_Decoder(nn.Module):\n",
    "    '''\n",
    "    Denoising decoder: single dense hidden layer followed by \n",
    "    output layer with a sigmoid to squish values\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DN_Decoder, self).__init__()\n",
    "        ## WRITE CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## WRITE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning your Denoising Autoencoder \n",
    "\n",
    "Start from the training procedure used in Part 1 for the autoencoder and extend this to get your denoising autoencoder working. Again, include images of both the data with added noise as well as the reconstructed images in the submitted notebook. Regarding the noise to add to your images, add Gaussian noise with a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE CODE HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
