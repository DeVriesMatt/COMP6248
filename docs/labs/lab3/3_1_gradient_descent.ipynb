{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fd2c27ac75b58ab9cfdb05285bcf0292",
     "grade": false,
     "grade_id": "cell-9eeeb7abc468a506",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 1: Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7515d498d97561d9884b0802387b3be4",
     "grade": false,
     "grade_id": "cell-52980e134e2f9e19",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In this lab we will implement some of the optimisation methods we learned in the lecture. First, we will start by revisiting gradient descent for linear regression. However, in this implementation we will observe how the model parameters are updated over iterations of the gradient descent algorithm. \n",
    "\n",
    "Let's start by implementing gradient descent on a simple linear regression dataset, like the one you generated in Lab 1, but this time shifted so that it ranges from -5 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "077b88381e9f7f22259ca4bb53c48583",
     "grade": true,
     "grade_id": "cell-02c39c20df2f2d24",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0b22b69e67951075996148ee0cb75f26",
     "grade": false,
     "grade_id": "cell-4c65a1279417a414",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You should now have data points according to y = mx + b where m = theta_true[0,0] and b = theta_true[1,0]. Note, $m = \\theta_1$ and $b = \\theta_0$.\n",
    "\n",
    "Now, let's implement gradient descent using the Mean Squared Error (MSE) cost function. \n",
    "\n",
    "Recall that: \n",
    "\n",
    "$J(\\theta) = \\frac{1}{2 M} \\sum_{i = 1}^M (h_{\\theta} (x^{(i)}) - y^{(i)} )^2$\n",
    "\n",
    "for $i = 1 \\text{  to iters (or until convergence)}$ <br>\n",
    "\n",
    "$\\hspace{1cm} w_i \\leftarrow w_i - \\eta \\frac{\\partial J}{\\partial w_i}$\n",
    "\n",
    "Implement the functions below in order to plot the cost function as well as the weight updates over iterations of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2334227b9dc660dc8c9f8910d7f9700d",
     "grade": true,
     "grade_id": "cell-a52e2455d84ff4da",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "81607b0b07d30d5873cfc349f49a5000",
     "grade": false,
     "grade_id": "cell-d0cb37c31097d491",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now let's plot the updates to see what is happening as we iterate over the algorithm. First, we will plot $J$ as a function of $\\theta_1$ as well as the resulting equation of the line learned over $N=5$ iterations. Once your code is working, modify the value of $\\eta$ to see how it affects convergence.\n",
    "\n",
    "The figure below illustrates what you're aiming to plot. Note, much of the code to generate the figures is given below, you mostly need to complete the 3 functions above and then fill in a few missing lines of code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "098ec9793226d21002cd0538a93a87e3",
     "grade": false,
     "grade_id": "cell-32de56d64c670852",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<img src=\"Figure1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b50e9a89855e23ac6ffc655323c55876",
     "grade": false,
     "grade_id": "cell-59662fa076965410",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### First generate the figure on the left hand side. This plot shows the data and the linear fit of the data as the model parameters change over the 5 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "aecf88b295519c54cfa59b302b7a5b44",
     "grade": true,
     "grade_id": "cell-7663cd58d1e91c37",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eaa1ff5b63e1b744b02ea8afa8c533a5",
     "grade": false,
     "grade_id": "cell-e7fd81fa921c6327",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Next, generate the plots on the right hand side. This figure is a plot of the cost function over the value of $\\theta_1$ as well as the updates of $\\theta_1$ over iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "10783d8f6f0d819c05b06c55433ebe5f",
     "grade": true,
     "grade_id": "cell-c9fa638485b0726e",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d06192ebc2f3cc31e5c1d42b924f1283",
     "grade": false,
     "grade_id": "cell-e70124241b132a09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Finally, generate a contour plot of the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cdd95a3c56c5aea03e4098f17ee5e67f",
     "grade": true,
     "grade_id": "cell-83e4d7737cbda3d1",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
